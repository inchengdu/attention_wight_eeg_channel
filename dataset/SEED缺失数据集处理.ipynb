{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEED dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_lens=200  # 每个数据小段的数据量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path : save floader of dataset\n",
    "# load_path : Pre-processed data storage floader\n",
    "files_dirct=\"G:\\\\dataset\\\\hight\\\\seed_v\\\\precessing_data\\\\train\"\n",
    "save_path=\"\"\n",
    "file_name=os.listdir(files_dirct)\n",
    "seg_lens=200\n",
    "range_channel=np.arange(0,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lack_math(raw,lack_c):\n",
    "    # print(\"raw \",raw.shape)\n",
    "    sort1=range_channel[0:lack_c].copy()\n",
    "    sort2=range_channel[lack_c+1:].copy()\n",
    "    sort3=np.array([lack_c])\n",
    "    sort=np.concatenate((sort1,sort2,sort3),axis=0)\n",
    "    full_data=raw.copy()\n",
    "    full_data[lack_c]=0\n",
    "    full_data=np.delete(full_data,lack_c,axis=0)\n",
    "    real=raw[lack_c].copy()\n",
    "    zero=np.zeros((1,seg_lens))\n",
    "    full_data=np.append(full_data,zero,axis=0)\n",
    "    return full_data,real,sort\n",
    "\n",
    "def segment(file_name):\n",
    "    file_npy=files_dirct+\"\\\\\"+file_name\n",
    "    file_data=np.load(file_npy)\n",
    "    data_arry=np.zeros((1,17,seg_lens)) \n",
    "    full_lens=file_data.shape[-1]\n",
    "    print(\"lens \",full_lens)\n",
    "    full_lens=int(full_lens/(seg_lens))\n",
    "    for i in range(full_lens-1):\n",
    "        if i%1000==1:\n",
    "            print(\"filename: \",file_name,\"  : : \",i,\"/\",full_lens,\" time : :\",time.strftime('%H %M %S',time.localtime()))\n",
    "        temple=file_data[:,i*seg_lens:(i+1)*seg_lens].copy()\n",
    "        temple_expand=np.expand_dims(temple,axis=0)\n",
    "        data_arry=np.concatenate([data_arry,temple_expand],axis=0)\n",
    "        # print(file_name,\"  \",data_arry.shape)\n",
    "    # data_arry=data_arry[1:]\n",
    "    save_seg_name=\"G:\\\\dataset\\\\hight\\\\seed_v\\\\preprocessed_seg_data\\\\\"+\"full_\"+file_name[:-4]+\".npy\"\n",
    "    np.save(save_seg_name,data_arry)\n",
    "    print(\"return : :  \",data_arry.shape)\n",
    "    return data_arry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lack(file_name_one):\n",
    "    data_seg=segment(file_name_one)\n",
    "    print(\"data_seg \",data_seg.shape)\n",
    "    number_seg=len(data_seg)\n",
    "    full_data=np.zeros((1,17,seg_lens))\n",
    "    real_data=np.zeros((1,seg_lens))\n",
    "    sort_data=np.zeros((1,17))\n",
    "    channel_number=np.zeros((1,1))\n",
    "    # print(\"orginal : :\",channel_number.shape)\n",
    "    for i in range(number_seg):\n",
    "        if i%1000==1:\n",
    "            print(\"filename : \",file_name_one,\" : : : \",i,\"/\",number_seg,\"   \",time.strftime('%H %M %S',time.localtime()))\n",
    "        lack_channel=random.randint(1,16)\n",
    "        lack_channel_exp=np.expand_dims(lack_channel,axis=(0,1))\n",
    "        # print(\"lack_channel_exp \",lack_channel_exp.shape)\n",
    "        channel_number=np.concatenate([channel_number,lack_channel_exp],axis=0)\n",
    "        full_data_t,real_data_t,sort_data_t=lack_math(data_seg[i,:,:],lack_channel)\n",
    "        full_data_t_exp=np.expand_dims(full_data_t,axis=0)\n",
    "        real_data_t_exp=np.expand_dims(real_data_t,axis=0)\n",
    "        sort_data_t_exp=np.expand_dims(sort_data_t,axis=0)\n",
    "        full_data=np.concatenate([full_data,full_data_t_exp],axis=0)\n",
    "        real_data=np.concatenate([real_data,real_data_t_exp],axis=0)\n",
    "        sort_data=np.concatenate([sort_data,sort_data_t_exp],axis=0)\n",
    "    full_data=full_data[2:]\n",
    "    real_data=real_data[2:]\n",
    "    sort_data=sort_data[2:]\n",
    "    # channel_number=channel_number[2:]\n",
    "    save_file_name_full=save_path+\"full_\"+file_name_one[:-4]+'.npy'\n",
    "    save_file_name_real=save_path+file_name_one[:-4]+'.npy'\n",
    "    save_file_name_channel=save_path+file_name_one[:-4]+'.npy'\n",
    "    print(\"full_data : : \",full_data.shape)\n",
    "    print(\"real_data : : \",real_data.shape)\n",
    "    print(\"channel_num : \",sort_data.shape)\n",
    "    np.save(save_file_name_full,full_data)\n",
    "    np.save(save_file_name_real,real_data)\n",
    "    np.save(save_file_name_channel,sort_data)\n",
    "    print(\"_______ \",file_name_one,\" ___________ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lack(file_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a61ded091e49bac219c59beecc96d030eb2f39d76b7087ad025c76f0f785cb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
